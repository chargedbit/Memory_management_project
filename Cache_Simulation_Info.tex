\documentclass[11pt, a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{xcolor}
\usepackage{geometry}
\usepackage{titlesec}
\usepackage{enumitem}
\usepackage{tcolorbox}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{amsmath}

% Page Geometry
\geometry{left=2cm, right=2cm, top=2cm, bottom=2cm}

% Colors
\definecolor{primary}{RGB}{0, 85, 164}      % Classic Blue
\definecolor{secondary}{RGB}{0, 128, 64}    % Green
\definecolor{accent}{RGB}{204, 0, 0}        % Red
\definecolor{codebg}{RGB}{245, 245, 245}
\definecolor{boxbg}{RGB}{236, 243, 255}

% Formatting
\titleformat{\section}
{\color{primary}\normalfont\Large\bfseries}
{\thesection}{1em}{}

\titleformat{\subsection}
{\color{secondary}\normalfont\large\bfseries}
{\thesubsection}{1em}{}

% Listings
\lstset{
    backgroundcolor=\color{codebg},
    basicstyle=\ttfamily\small,
    frame=none,
    numbers=left,
    numberstyle=\tiny\color{gray},
    breaklines=true,
    showstringspaces=false
}

\begin{document}

\begin{titlepage}
    \centering
    \vspace*{2cm}
    {\Huge\bfseries\color{primary} Cache Simulation Documentation}\\[1cm]
    {\Large\itshape A Comprehensive Guide to Architecture, Policies, and Metrics}\\[2cm]
    
    \begin{tcolorbox}[colback=boxbg, colframe=primary, arc=5pt, boxrule=1pt, width=0.9\textwidth]
        \centering
        \large This document details the implementation of the Multi-Level CPU Cache Simulator, 
        explaining configuration parameters, internal simulation logic, replacement policies with examples, 
        and statistical analysis.
    \end{tcolorbox}
    
    \vfill
    {\large Generated for \textbf{Memory Management Simulation Tool}}
\end{titlepage}

\tableofcontents
\newpage

\section{Configuring the Cache Hierarchy}

The simulator provides a powerful command to define the geometry of the L1 and L2 caches. Understanding these parameters is crucial for analyzing performance.

\subsection{The Command Structure}
\begin{tcolorbox}[colback=codebg, colframe=black, title=\textbf{Command Syntax}]
\texttt{init cache <L1\_Size> <L1\_Block> <L1\_Ways> <L2\_Size> <L2\_Block> <L2\_Ways>}
\end{tcolorbox}

\subsection{Parameter Breakdown}

\begin{description}[style=multiline, leftmargin=3cm]
    \item[\color{primary} Size (Bytes)] 
    The total capacity of the cache level. 
    \begin{itemize}
        \item Does it hold the data you need?
        \item \textbf{Example:} \texttt{1024} creates a 1KB cache.
    \end{itemize}

    \item[\color{primary} Block Size] 
    (or Line Size). The smallest unit of data transferred between memory and cache.
    \begin{itemize}
        \item Larger blocks exploit \textit{Spatial Locality} (retrieving neighbors effectively) but cost more fetch time.
        \item \textbf{Example:} \texttt{32} means every miss fetches 32 contiguous bytes.
    \end{itemize}

    \item[\color{primary} Ways (Associativity)] 
    Determines \textit{where} a block can be placed.
    \begin{itemize}
        \item \textbf{1 Way (Direct Mapped):} A block maps to ONE specific slot. (High conflict misses).
        \item \textbf{N Ways (Set Associative):} A block maps to a \textit{Single Set}, but can occupy any of the $N$ slots (ways) in that set. (Flexible).
        \item \textbf{Example:} \texttt{2} means 2-Way Set Associative.
    \end{itemize}
\end{description}

\begin{tcolorbox}[colback=white, colframe=secondary, title=\textbf{Calculation Example}]
\textbf{Configuration:} \texttt{Size=1024, Block=32, Ways=2}
\begin{itemize}
    \item \textbf{Total Blocks} = $1024 / 32 = 32$ blocks.
    \item \textbf{Number of Sets} = $32 \text{ blocks} / 2 \text{ ways} = 16$ sets.
    \item \textbf{Mapping:} Address $A$ maps to set $(A / 32) \% 16$.
\end{itemize}
\end{tcolorbox}

\section{Simulation Logic: Hits & Misses}

The simulator follows a strict hierarchy for every memory access.

\subsection{Execution Flow}
When you run \texttt{access <virtual\_address>}:

\begin{enumerate}
    \item \textbf{Translate:} Virtual Address $\to$ Physical Address (via Page Table).
    \item \textbf{Probe L1:} Check if data exists in L1.
    \begin{itemize}
        \item \textbf{\color{secondary} HIT:} Return success. Update L1 stats (Hits +1). Update Replacement Policy order.
        \item \textbf{\color{accent} MISS:} Proceed to L2.
    \end{itemize}
    \item \textbf{Probe L2 (on L1 Miss):}
    \begin{itemize}
        \item \textbf{\color{secondary} HIT:} Data found in L2. Return success. Update L2 stats (Hits +1).
        \item \textbf{\color{accent} MISS:} Proceed to Main Memory. Update L2 stats (Misses +1).
    \end{itemize}
    \item \textbf{Fill (Allocation):}
    \begin{itemize}
        \item If L2 Missed: Load data from Memory $\to$ L2.
        \item If L1 Missed: Load data from L2 $\to$ L1.
        \item \textit{Note: Allocation may trigger \textbf{Eviction} if the set is full.}
    \end{itemize}
\end{enumerate}

\section{Replacement Policies & Examples}

When a new block must be loaded into a full set, a \textbf{Victim} must be chosen. 
Command: \texttt{set cache\_policy <policy>}

\subsection{1. FIFO (First-In, First-Out)}
\textbf{Logic:} Evict the block that was inserted \textit{earliest}. Accessing an existing block \textbf{does not} change its age.
\\[5pt]
\textbf{Scenario:} Set can hold 3 items. Sequence: A, B, C, A, D.
\begin{itemize}
    \item \texttt{Load A, B, C}: Cache = [A, B, C].
    \item \texttt{Access A}: Hit. Cache = [A, B, C]. (A is still oldest).
    \item \texttt{Load D}: Miss. Evict Oldest (A). Cache = [B, C, D].
\end{itemize}

\subsection{2. LRU (Least Recently Used)}
\textbf{Logic:} Evict the block that hasn't been used for the longest time. Every access moves a block to the "Newest" position.
\\[5pt]
\textbf{Scenario:} Set can hold 3 items. Sequence: A, B, C, A, D.
\begin{itemize}
    \item \texttt{Load A, B, C}: Cache = [A, B, C] (A is oldest used).
    \item \texttt{Access A}: Hit. A becomes Newest. Order = [B, C, A].
    \item \texttt{Load D}: Miss. Evict LRU (B). Order = [C, A, D].
\end{itemize}
\textit{Note: LRU is usually better than FIFO for temporal locality.}

\subsection{3. LFU (Least Frequently Used)}
\textbf{Logic:} Evict the block with the lowest access count.
\\[5pt]
\textbf{Scenario:} Set can hold 3 items.
\begin{itemize}
    \item A (used 10x), B (used 2x), C (used 10x).
    \item \texttt{Load D}: Evict B (lowest count).
    \item \textit{Problem:} "Ghost" entries. If A was used 1000 times yesterday but never again, LFU keeps it forever over new useful data.
\end{itemize}

\section{Understanding Statistics}

The \texttt{stats} command provides deep insights.

\subsection{Basic Metrics}
\begin{itemize}
    \item \textbf{Hits/Misses:} Raw counts of outcomes.
    \item \textbf{Hit Ratio (\%):} $\frac{\text{Hits}}{\text{Hits} + \text{Misses}} \times 100$. Higher is better.
    \item \textbf{Evictions:} Number of times a valid block was removed to make space. High evictions imply the cache is too small (capacity miss) or has bad associativity (conflict miss).
\end{itemize}

\subsection{Advanced Metrics}

\subsubsection{Miss Traffic}
This is the number of requests sent to the \textbf{Next Lower Level}.
\begin{itemize}
    \item \textbf{L1 Miss Traffic:} Requests sent to L2. 
    \item \textbf{L2 Miss Traffic:} Requests sent to Main Memory (Slow!).
    \item \textit{Why it matters:} Even if L1 has a 90\% hit rate, if the 10\% miss traffic crashes specific L2 sets, performance suffers.
\end{itemize}

\subsubsection{AMAT (Average Memory Access Time)}
The ultimate performance score. It represents the average latency seen by the CPU for a memory request.

\[ \text{AMAT} = T_{L1} + (MR_{L1} \times T_{L2}) + (MR_{L1} \times MR_{L2} \times T_{Mem}) \]

Where:
\begin{itemize}
    \item $T_X$: Access Time (Latency) of level X.
    \item $MR_X$: Miss Rate of level X ($1 - \text{HitRatio}$).
\end{itemize}

\textbf{Our Default Latencies:}
\begin{itemize}
    \item L1 Loop: 1 cycle
    \item L2 Loop: 10 cycles
    \item Memory: 100 cycles
\end{itemize}

\begin{tcolorbox}[colback=white, colframe=primary, title=\textbf{AMAT Optimization Goal}]
To lower AMAT, you must either:
\begin{enumerate}
    \item Reduce Miss Rate ($MR_{L1}$ is most critical).
    \item Reduce Latency (Hardware fixed, but avoiding Memory access is key).
\end{enumerate}
\end{tcolorbox}

\end{document}
